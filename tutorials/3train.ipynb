{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练你自己的动作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "在这一部分，你将导入必要的库并定义几个函数来预处理训练图像，将其转换为包含关键点坐标和真实标签的CSV文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用MoveNet执行姿势估计的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')\n",
    "sys.path.append(pose_sample_rpi_path)\n",
    "\n",
    "# 加载MoveNet Thunder模型\n",
    "import utils\n",
    "from data import BodyPart\n",
    "from ml import Movenet\n",
    "movenet = Movenet('movenet_thunder')\n",
    "\n",
    "# 定义函数以使用MoveNet Thunder进行姿势估计\n",
    "def detect(input_tensor, inference_count=3):\n",
    "  image_height, image_width, channel = input_tensor.shape\n",
    "  movenet.detect(input_tensor.numpy(), reset_crop_region=True)\n",
    "  for _ in range(inference_count - 1):\n",
    "    person = movenet.detect(input_tensor.numpy(), reset_crop_region=False)\n",
    "  return person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化姿势估计结果的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction_on_image(image, person, crop_region=None, close_figure=True, keep_input_size=False):\n",
    "  image_np = utils.visualize(image, [person])\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  im = ax.imshow(image_np)\n",
    "  if close_figure:\n",
    "    plt.close(fig)\n",
    "  if not keep_input_size:\n",
    "    image_np = utils.keep_aspect_ratio_resizer(image_np, (512, 512))\n",
    "  return image_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载图像，检测姿势关键点并保存到CSV文件中的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveNetPreprocessor(object):\n",
    "  def __init__(self, images_in_folder, images_out_folder, csvs_out_path):\n",
    "    self._images_in_folder = images_in_folder\n",
    "    self._images_out_folder = images_out_folder\n",
    "    self._csvs_out_path = csvs_out_path\n",
    "    self._messages = []\n",
    "    self._csvs_out_folder_per_class = tempfile.mkdtemp()\n",
    "    self._pose_class_names = sorted([n for n in os.listdir(self._images_in_folder) if not n.startswith('.')])\n",
    "\n",
    "  def process(self, per_pose_class_limit=None, detection_threshold=0.1):\n",
    "    for pose_class_name in self._pose_class_names:\n",
    "      print('Preprocessing', pose_class_name, file=sys.stderr)\n",
    "      images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
    "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder_per_class, pose_class_name + '.csv')\n",
    "      if not os.path.exists(images_out_folder):\n",
    "        os.makedirs(images_out_folder)\n",
    "      with open(csv_out_path, 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        image_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "        if per_pose_class_limit is not None:\n",
    "          image_names = image_names[:per_pose_class_limit]\n",
    "        valid_image_count = 0\n",
    "        for image_name in tqdm.tqdm(image_names):\n",
    "          image_path = os.path.join(images_in_folder, image_name)\n",
    "          try:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "          except:\n",
    "            self._messages.append('Skipped ' + image_path + '. Invalid image.')\n",
    "            continue\n",
    "          else:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.io.decode_jpeg(image)\n",
    "            image_height, image_width, channel = image.shape\n",
    "          if channel != 3:\n",
    "            self._messages.append('Skipped ' + image_path + '. Image isn\\'t in RGB format.')\n",
    "            continue\n",
    "          person = detect(image)\n",
    "          min_landmark_score = min([keypoint.score for keypoint in person.keypoints])\n",
    "          should_keep_image = min_landmark_score >= detection_threshold\n",
    "          if not should_keep_image:\n",
    "            self._messages.append('Skipped ' + image_path + '. No pose was confidently detected.')\n",
    "            continue\n",
    "          valid_image_count += 1\n",
    "          output_overlay = draw_prediction_on_image(image.numpy().astype(np.uint8), person, close_figure=True, keep_input_size=True)\n",
    "          output_frame = cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR)\n",
    "          cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
    "          pose_landmarks = np.array([[keypoint.coordinate.x, keypoint.coordinate.y, keypoint.score] for keypoint in person.keypoints], dtype=np.float32)\n",
    "          coordinates = pose_landmarks.flatten().astype(str).tolist()\n",
    "          csv_out_writer.writerow([image_name] + coordinates)\n",
    "        if not valid_image_count:\n",
    "          raise RuntimeError('No valid images found for the \"{}\" class.'.format(pose_class_name))\n",
    "    print('\\n'.join(self._messages))\n",
    "    all_landmarks_df = self._all_landmarks_as_dataframe()\n",
    "    all_landmarks_df.to_csv(self._csvs_out_path, index=False)\n",
    "\n",
    "  def class_names(self):\n",
    "    return self._pose_class_names\n",
    "\n",
    "  def _all_landmarks_as_dataframe(self):\n",
    "    total_df = None\n",
    "    for class_index, class_name in enumerate(self._pose_class_names):\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder_per_class, class_name + '.csv')\n",
    "      per_class_df = pd.read_csv(csv_out_path, header=None)\n",
    "      per_class_df['class_no'] = [class_index]*len(per_class_df)\n",
    "      per_class_df['class_name'] = [class_name]*len(per_class_df)\n",
    "      per_class_df[per_class_df.columns[0]] = (os.path.join(class_name, '') + per_class_df[per_class_df.columns[0]].astype(str))\n",
    "      if total_df is None:\n",
    "        total_df = per_class_df\n",
    "      else:\n",
    "        total_df = pd.concat([total_df, per_class_df], axis=0)\n",
    "    list_name = [[bodypart.name + '_x', bodypart.name + '_y', bodypart.name + '_score'] for bodypart in BodyPart]\n",
    "    header_name = []\n",
    "    for columns_name in list_name:\n",
    "      header_name += columns_name\n",
    "    header_name = ['file_name'] + header_name\n",
    "    header_map = {total_df.columns[i]: header_name[i] for i in range(len(header_name))}\n",
    "    total_df.rename(header_map, axis=1, inplace=True)\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第1部分：预处理输入图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们的姿势分类器的输入是MoveNet模型的输出关键点，我们需要通过MoveNet运行已标记的图像，并将所有关键点数据和真实标签捕获到CSV文件中来生成我们的训练数据集。\n",
    "\n",
    "我们为本教程提供的数据集是一个CG生成的瑜伽姿势数据集。它包含多个CG生成的模型在做5种不同瑜伽姿势的图像。目录已经分为`train`数据集和`test`数据集。\n",
    "\n",
    "因此，在本节中，我们将下载瑜伽数据集并通过MoveNet运行，以便我们可以将所有关键点捕获到CSV文件中... **然而，将我们上千张文件的数据集输入MoveNet并生成这个CSV文件大约需要10分钟**。所以作为替代方案，你可以通过设置下面的`is_skip_step_1`参数为**True**，下载一个现成的瑜伽数据集的CSV文件。这样你将跳过此步骤，而是下载将在此预处理步骤中创建的相同CSV文件。\n",
    "\n",
    "想用自己的图像数据集训练姿势分类器，你需要上传你的图像并运行此预处理步骤按照以下说明上传你自己的姿势数据集。\n",
    "\n",
    "1. 准备一个包含你的图像数据集文件夹的压缩文件(ZIP、TAR或其他)。如果你的数据集尚未拆分，将根据指定的拆分比例进行拆分。也就是说，你上传的图像文件夹应如下所示：\n",
    "  ```\n",
    "  yoga_poses/\n",
    "  |__ downdog/\n",
    "      |______ 00000128.jpg\n",
    "      |______ 00000181.jpg\n",
    "      |______ ...\n",
    "  |__ goddess/\n",
    "      |______ 00000243.jpg\n",
    "      |______ 00000306.jpg\n",
    "      |______ ...\n",
    "  ```\n",
    "1. 选择你的压缩文件并等待上传完成后再继续。\n",
    "2. 编辑以下代码块以指定你的压缩文件和图像目录的名称（默认情况下，我们期望一个ZIP文件，因此如果你的压缩文件是其他格式，也需要修改该部分）。\n",
    "3. 现在运行其余的笔记本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "innox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
