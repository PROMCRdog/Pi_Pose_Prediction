{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制作你自己的 **AI** 动作识别系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设备：香橙派 Zero 3 （同时执行太多任务可能会导致设备卡顿）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNU/Linux 的基本操作\n",
    "\n",
    ">GNU 是 \"GNU's Not Unix!\" 的递归缩写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ctrl + alt + t` 打开终端\n",
    "\n",
    "`ctrl + alt + F1-F7` 切换虚拟终端 tty1-7, 通常tty7号是图形界面\n",
    "\n",
    "`ctrl + c` 结束指令，终止运行\n",
    "\n",
    "`ls` 查看此目录下的所有文件与文件夹，尝试 `ls -a`, `ls -l`, `ls -lh` （-h = --human-readable，人类可读）\n",
    "\n",
    "`man` *manual* 或指令后面加 `--help` 查看指令说明书 \n",
    "\n",
    "`pwd` *print working directory* 输出所在目录\n",
    "\n",
    "`code .` (装好vscode的前提下) 从此目录打开vscode\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置开发环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory: /Users/promcrdog/Documents/Vector lab/Class - pose detection/Pi_Pose_Prediction/inference_prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "# Change the directory 切换执行路径\n",
    "new_dir = \"./inference_prediction\"\n",
    "os.chdir(new_dir)\n",
    "# Verify the new directory 确认执行路径\n",
    "changed_dir = os.getcwd()\n",
    "print(f\"Changed directory: {changed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初步测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到摄像头编号index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for camera_id in range(0, 20):\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    if cap is None or not cap.isOpened():\n",
    "        # print(f\"No camera found at index {camera_id}\")\n",
    "        continue\n",
    "    else:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            print(f\"camera found at index {camera_id}\")\n",
    "        cap.release()\n",
    "\n",
    "cv2.destroyWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded variables 硬编变量\n",
    "ESTIMATION_MODEL = 'movenet_lightning'  # 估计模型\n",
    "TRACKER_TYPE = 'bounding_box'  # 跟踪器类型 ('keypoint' or 'bounding_box')\n",
    "CLASSIFICATION_MODEL = 'posenet.tflite'  # Set to None if not using a classifier 如果不使用分类器，设置为None\n",
    "LABEL_FILE = 'labels.txt'  # 标签文件\n",
    "CAMERA_ID = 0  # 相机ID\n",
    "WIDTH = 640  # 宽度\n",
    "HEIGHT = 480  # 高度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "import cv2\n",
    "from ml import Classifier\n",
    "from ml import Movenet\n",
    "from ml import MoveNetMultiPose\n",
    "from ml import Posenet\n",
    "import utils as utils\n",
    "\n",
    "# Change the directory\n",
    "new_dir = \"./inference_prediction\"\n",
    "os.chdir(new_dir)\n",
    "\n",
    "def run(estimation_model: str, tracker_type: str, classification_model: str,\n",
    "        label_file: str, camera_id: int, width: int, height: int) -> None:\n",
    "    \"\"\"\n",
    "    Continuously run inference on images acquired from the camera.\n",
    "    连续对从相机获取的图像进行推理。\n",
    "    \"\"\"\n",
    "\n",
    "    # Notify users that tracker is only enabled for MoveNet MultiPose model.\n",
    "    # 通知用户跟踪器仅适用于MoveNet MultiPose模型。\n",
    "    if tracker_type and (estimation_model != 'movenet_multipose'):\n",
    "        logging.warning(\n",
    "            'No tracker will be used as tracker can only be enabled for '\n",
    "            'MoveNet MultiPose model.'\n",
    "            '跟踪器只能用于MoveNet MultiPose模型。'\n",
    "        )\n",
    "\n",
    "    # Initialize the pose estimator selected.\n",
    "    # 初始化选姿势预测器。\n",
    "    if estimation_model in ['movenet_lightning', 'movenet_thunder']:\n",
    "        pose_detector = Movenet(estimation_model)\n",
    "    elif estimation_model == 'posenet':\n",
    "        pose_detector = Posenet(estimation_model)\n",
    "    elif estimation_model == 'movenet_multipose':\n",
    "        pose_detector = MoveNetMultiPose(estimation_model, tracker_type)\n",
    "    else:\n",
    "        sys.exit('ERROR: Model is not supported. 错误：不支持该模型。')\n",
    "\n",
    "    # Variables to calculate FPS\n",
    "    # 计算FPS的变量\n",
    "    counter, fps = 0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Start capturing video input from the camera\n",
    "    # 开始从相机捕获视频输入\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "    # Visualization parameters\n",
    "    # 可视化参数\n",
    "    row_size = 20  # pixels 像素\n",
    "    left_margin = 24  # pixels 像素\n",
    "    text_color = (0, 0, 255)  # red 红色\n",
    "    font_size = 1\n",
    "    font_thickness = 1\n",
    "    classification_results_to_show = 3\n",
    "    fps_avg_frame_count = 10\n",
    "    keypoint_detection_threshold_for_classifier = 0.1\n",
    "    classifier = None\n",
    "\n",
    "    # Initialize the classification model\n",
    "    # 初始化分类模型\n",
    "    if classification_model:\n",
    "        classifier = Classifier(classification_model, label_file)\n",
    "        classification_results_to_show = min(classification_results_to_show,\n",
    "                                             len(classifier.pose_class_names))\n",
    "\n",
    "    # Continuously capture images from the camera and run inference\n",
    "    # 持续从相机捕获图像并进行推理\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            sys.exit(\n",
    "                'ERROR: Unable to read from webcam. Please verify your webcam settings.'\n",
    "                '错误：无法从网络摄像头读取。请检查您的网络摄像头设置。'\n",
    "            )\n",
    "\n",
    "        counter += 1\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        if estimation_model == 'movenet_multipose':\n",
    "            # Run pose estimation using a MultiPose model.\n",
    "            # 使用MultiPose模型进行姿势估计。\n",
    "            list_persons = pose_detector.detect(image)\n",
    "        else:\n",
    "            # Run pose estimation using a SinglePose model, and wrap the result in an array.\n",
    "            # 使用SinglePose模型进行姿势估计，并将结果包装在数组中。\n",
    "            list_persons = [pose_detector.detect(image)]\n",
    "\n",
    "        # Draw keypoints and edges on input image\n",
    "        # 在输入图像上绘制关键点和边缘\n",
    "        image = utils.visualize(image, list_persons)\n",
    "\n",
    "        if classifier:\n",
    "            # Check if all keypoints are detected before running the classifier.\n",
    "            # If there's a keypoint below the threshold, show an error.\n",
    "            # 在运行分类器之前检查是否检测到所有关键点。\n",
    "            # 如果有关键点低于阈值，显示错误。\n",
    "            person = list_persons[0]\n",
    "            min_score = min([keypoint.score for keypoint in person.keypoints])\n",
    "            if min_score < keypoint_detection_threshold_for_classifier:\n",
    "                error_text = 'Some keypoints are not detected. 一些关键点未被检测到。'\n",
    "                text_location = (left_margin, 2 * row_size)\n",
    "                cv2.putText(image, error_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                            font_size, text_color, font_thickness)\n",
    "                error_text = 'Make sure the person is fully visible in the camera. 确保相机中完全可见人物。'\n",
    "                text_location = (left_margin, 3 * row_size)\n",
    "                cv2.putText(image, error_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                            font_size, text_color, font_thickness)\n",
    "            else:\n",
    "                # Run pose classification\n",
    "                # 运行姿势分类\n",
    "                prob_list = classifier.classify_pose(person)\n",
    "\n",
    "                # Show classification results on the image\n",
    "                # 在图像上显示分类结果\n",
    "                for i in range(classification_results_to_show):\n",
    "                    class_name = prob_list[i].label\n",
    "                    probability = round(prob_list[i].score, 2)\n",
    "                    result_text = class_name + ' (' + str(probability) + ')'\n",
    "                    text_location = (left_margin, (i + 2) * row_size)\n",
    "                    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                                font_size, text_color, font_thickness)\n",
    "\n",
    "        # Calculate the FPS\n",
    "        # 计算FPS\n",
    "        if counter % fps_avg_frame_count == 0:\n",
    "            end_time = time.time()\n",
    "            fps = fps_avg_frame_count / (end_time - start_time)\n",
    "            start_time = time.time()\n",
    "\n",
    "        # Show the FPS\n",
    "        # 显示FPS\n",
    "        fps_text = 'FPS = ' + str(int(fps))\n",
    "        text_location = (left_margin, row_size)\n",
    "        cv2.putText(image, fps_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                    font_size, text_color, font_thickness)\n",
    "\n",
    "        # Stop the program if the ESC key is pressed.\n",
    "        # 如果按下ESC键，停止程序。\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        cv2.imshow(estimation_model, image)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the pose estimation and classification.\n",
    "    运行姿势估计和分类的主函数。\n",
    "    \"\"\"\n",
    "    run(ESTIMATION_MODEL, TRACKER_TYPE, CLASSIFICATION_MODEL, LABEL_FILE, CAMERA_ID, WIDTH, HEIGHT)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change back to initiall working directory\n",
    "os.chdir(current_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "innox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
